{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Path to directory with images\n",
    "dataDir = './Images_03a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open noisy image\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_03_noisy.jpg'))\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Filtering and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Check tutorial here!](https://docs.opencv.org/4.x/dc/dd3/tutorial_gausian_median_blur_bilateral_filter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mean filter to the image\n",
    "img_mean_filter = cv2.blur(img, (4, 4))\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img_mean_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Gaussian filter to the image\n",
    "img_gaussian_filter = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img_gaussian_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1: Apply median and bilateral filters to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a median filter\n",
    "img_median_filter = cv2.medianBlur(img, 9)\n",
    "\n",
    "# Show image after median filtering\n",
    "cv2.imshow('Median Filtered Image', img_median_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Median Filtered Image')\n",
    "\n",
    "# Apply a bilateral filter to the image\n",
    "img_bilateral_filter = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "# Show image after bilateral filtering\n",
    "cv2.imshow('image_bilateral_filter', img_bilateral_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image_bilateral_filter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2: Add salt and pepper noise to a grayscale image and check the result of previous filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(dataDir, 'coins_02.jpg'))\n",
    "\n",
    "# Convert to grayscale\n",
    "grayscale_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "h, w = grayscale_img.shape\n",
    "num_pixels = h * w\n",
    "num_pixels_to_alter = int(num_pixels * 0.05)\n",
    "\n",
    "pixels = np.random.randint(num_pixels, size=num_pixels_to_alter)\n",
    "\n",
    "# Get coordinates\n",
    "x = pixels % w\n",
    "y = pixels % h\n",
    "\n",
    "color = np.random.choice([0,1], num_pixels_to_alter)\n",
    "\n",
    "for i in range(num_pixels_to_alter):\n",
    "    grayscale_img[y[i], x[i]] = color[i]*255\n",
    "\n",
    "# Apply a median filter to the noisy image\n",
    "img_median_filter = cv2.medianBlur(grayscale_img, 5)\n",
    "\n",
    "# Apply a bilateral filter to the noisy image\n",
    "img_bilateral_filter = cv2.bilateralFilter(grayscale_img, 9, 75, 75)\n",
    "\n",
    "# Show the original noisy image\n",
    "cv2.imshow('Noisy Image', grayscale_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Noisy Image')\n",
    "\n",
    "# Show the image after median filtering\n",
    "cv2.imshow('Median Filter', img_median_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Median Filter')\n",
    "\n",
    "# Show the image after bilateral filtering\n",
    "cv2.imshow('Bilateral Filter', img_bilateral_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Bilateral Filter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.3: Reproduce gaussian blur with custom convolution (using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_02.jpg'))\n",
    "\n",
    "# Convert to grayscale\n",
    "grayscale_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Normalize image\n",
    "img_normalized = grayscale_img / 255\n",
    "\n",
    "# Define Gaussian kernel\n",
    "gaussian_kernel = np.array([[1,2,1],\n",
    "                            [2,4,2],\n",
    "                            [1,2,1]])\n",
    "\n",
    "# Normalize kernel\n",
    "gaussian_kernel = gaussian_kernel / np.sum(gaussian_kernel)\n",
    "\n",
    "# Apply convolution\n",
    "convolution_result = ndimage.convolve(img_normalized, gaussian_kernel)\n",
    "\n",
    "# Apply Gaussian blur\n",
    "gaussian_blur = cv2.GaussianBlur(grayscale_img, (3,3), 0)\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', grayscale_img)\n",
    "cv2.imshow('gaussian blur', gaussian_blur)\n",
    "cv2.imshow('convolution', convolution_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.4: Define custom convolution (using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_02.jpg'))\n",
    "\n",
    "# Convert to grayscale\n",
    "grayscale_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define a custom kernel for sharpening\n",
    "custom_kernel = np.array([[0, -1, 0],\n",
    "                          [-1, 5, -1],\n",
    "                          [0, -1, 0]])\n",
    "\n",
    "# Normalize kernel\n",
    "custom_kernel = custom_kernel / np.sum(custom_kernel)\n",
    "\n",
    "# Apply custom convolution\n",
    "convolution_result = ndimage.convolve(grayscale_img, custom_kernel)\n",
    "\n",
    "# Show images\n",
    "cv2.imshow('Original Image', grayscale_img)\n",
    "cv2.imshow('Custom Convolution Result', convolution_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.5: Add salt and pepper noise to a colored image and apply the previous filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_02.jpg'))\n",
    "\n",
    "# Get image dimensions\n",
    "h, w, _ = img.shape\n",
    "\n",
    "# Calculate the number of pixels to alter\n",
    "num_pixels = h * w\n",
    "num_pixels_to_alter = int(num_pixels * 0.05)\n",
    "\n",
    "# Generate random pixel coordinates\n",
    "pixels = np.random.randint(num_pixels, size=num_pixels_to_alter)\n",
    "\n",
    "# Get coordinates\n",
    "x = pixels % w\n",
    "y = pixels // w  # Note the correction here\n",
    "\n",
    "# Generate random colors (0 or 255) for salt and pepper noise\n",
    "colors = np.random.choice([0, 255], size=num_pixels_to_alter)\n",
    "\n",
    "# Apply salt and pepper noise\n",
    "for i in range(num_pixels_to_alter):\n",
    "    img[y[i], x[i]] = [colors[i]] * 3  # Apply the same color to all channels\n",
    "\n",
    "# Apply a median filter to the noisy image\n",
    "img_median_filter = cv2.medianBlur(img, 5)\n",
    "\n",
    "# Apply a bilateral filter to the noisy image\n",
    "img_bilateral_filter = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "# Define a custom kernel for sharpening\n",
    "custom_kernel = np.array([[0, -1, 0],\n",
    "                          [-1, 5, -1],\n",
    "                          [0, -1, 0]])\n",
    "\n",
    "# Apply custom convolution to each color channel separately\n",
    "convolution_result = np.zeros_like(img, dtype=np.float32)\n",
    "for i in range(3):\n",
    "    convolution_result[:, :, i] = ndimage.convolve(img[:, :, i].astype(np.float32), custom_kernel)\n",
    "\n",
    "# Clip the pixel values to ensure they are within the valid range\n",
    "convolution_result = np.clip(convolution_result, 0, 255)\n",
    "\n",
    "# Convert the result back to uint8 for visualization\n",
    "convolution_result_vis = convolution_result.astype(np.uint8)\n",
    "\n",
    "# Show the original noisy image\n",
    "cv2.imshow('Noisy Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Noisy Image')\n",
    "\n",
    "# Show the image after median filtering\n",
    "cv2.imshow('Median Filter', img_median_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Median Filter')\n",
    "\n",
    "# Show the image after bilateral filtering\n",
    "cv2.imshow('Bilateral Filter', img_bilateral_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Bilateral Filter')\n",
    "\n",
    "# Show the image after custom convolution\n",
    "cv2.imshow('Custom Convolution Result', convolution_result_vis)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.6: Apply custom filter to colored image with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_02.jpg'))\n",
    "\n",
    "# Get image dimensions\n",
    "h, w, _ = img.shape\n",
    "\n",
    "# Calculate the number of pixels to alter\n",
    "num_pixels = h * w\n",
    "num_pixels_to_alter = int(num_pixels * 0.05)\n",
    "\n",
    "# Generate random pixel coordinates\n",
    "pixels = np.random.randint(num_pixels, size=num_pixels_to_alter)\n",
    "\n",
    "# Get coordinates\n",
    "x = pixels % w\n",
    "y = pixels // w\n",
    "\n",
    "# Generate random colors (0 or 255) for salt and pepper noise\n",
    "colors = np.random.choice([0, 255], size=num_pixels_to_alter)\n",
    "\n",
    "# Apply salt and pepper noise\n",
    "for i in range(num_pixels_to_alter):\n",
    "    img[y[i], x[i]] = [colors[i]] * 3  # Apply the same color to all channels\n",
    "\n",
    "# Define a custom kernel for custom filtering\n",
    "custom_kernel = np.array([[0, -1, 0],\n",
    "                          [-1, 5, -1],\n",
    "                          [0, -1, 0]])\n",
    "\n",
    "# Normalize kernel\n",
    "custom_kernel = custom_kernel / np.sum(custom_kernel)\n",
    "\n",
    "# Apply custom convolution to each color channel separately\n",
    "filtered_image = np.zeros_like(img, dtype=np.float32)\n",
    "for i in range(3):\n",
    "    filtered_image[:, :, i] = ndimage.convolve(img[:, :, i].astype(np.float32), custom_kernel)\n",
    "\n",
    "# Clip the pixel values to ensure they are within the valid range\n",
    "filtered_image = np.clip(filtered_image, 0, 255)\n",
    "\n",
    "# Convert the result back to uint8 for visualization\n",
    "filtered_image = filtered_image.astype(np.uint8)\n",
    "\n",
    "# Show the original noisy image\n",
    "cv2.imshow('Noisy Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Noisy Image')\n",
    "\n",
    "# Show the image after custom filtering\n",
    "cv2.imshow('Filtered Image', filtered_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load low contrast image\n",
    "img = cv2.imread(os.path.join(dataDir, 'face_lowContrast_01.jpg'), 0) # Change this, according to your image's path\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Histograms Equalization](https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#ga7e54091f0c937d49bf84152a16f76d6e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing contrast with Histograms Equalization\n",
    "img_with_he = cv2.equalizeHist(img)\n",
    "\n",
    "cv2.imshow('histogram_equalization', img_with_he)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contrast Limited Adaptive Histogram Equalization](https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#gad689d2607b7b3889453804f414ab1018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing contrast with CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img_with_CLAHE = clahe.apply(img)\n",
    "\n",
    "cv2.imshow('clahe', img_with_CLAHE)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1: Apply Histogram Equalization to a colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the colored image\n",
    "img = cv2.imread(os.path.join(dataDir, 'apple.jpg'))\n",
    "\n",
    "# Split the image into channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Apply histogram equalization to each channel\n",
    "b_equalized = cv2.equalizeHist(b)\n",
    "g_equalized = cv2.equalizeHist(g)\n",
    "r_equalized = cv2.equalizeHist(r)\n",
    "\n",
    "# Merge the equalized channels back into the image\n",
    "img_equalized = cv2.merge((b_equalized, g_equalized, r_equalized))\n",
    "\n",
    "# Display the original and equalized images\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Equalized Image', img_equalized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2: Apply CLAHE to a colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the colored image\n",
    "img = cv2.imread(os.path.join(dataDir, 'apple.jpg'))\n",
    "\n",
    "# Convert the image to LAB color space\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split the LAB image into channels\n",
    "l, a, b = cv2.split(lab)\n",
    "\n",
    "# Apply CLAHE to the L channel\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "l_clahe = clahe.apply(l)\n",
    "\n",
    "# Merge the CLAHE enhanced L channel with the original A and B channels\n",
    "lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "\n",
    "# Convert the LAB image back to BGR color space\n",
    "img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Display the original and CLAHE enhanced images\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('CLAHE Enhanced Image', img_clahe)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
