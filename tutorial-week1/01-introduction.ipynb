{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction to OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first lab is to present a small introduction to image processing using OpenCV. In each section, you can find:\n",
    "* a small example - analyse the code and try it\n",
    "* some exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements for this tutorial\n",
    "! pip install opencv-python\n",
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you prefer, you can convert this notebook to a Python script by uncommenting the following command\n",
    "! pip install nbconvert\n",
    "! jupyter nbconvert --to script 01-introduction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataDir = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Images – read, write and display; ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Showing the image\n",
    "cv2.imshow(\"ml.jpg\", img)\n",
    "\n",
    "# Waiting for user to press a key to close the image\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close the window after user pressed a key\n",
    "cv2.destroyWindow(\"ml.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image size\n",
    "h, w, c = img.shape\n",
    "print(f'height: {h}')\n",
    "print(f'width: {w}')\n",
    "print(f'channels: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving image in bmp format\n",
    "cv2.imwrite('ml_new.bmp', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1 - Read any other color image from a file, show the mouse cursor over the image, and the coordinates and RGB components of the pixel under the cursor. When the user clicks on the mouse, let him modify the RGB components of the selected pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_color = (0, 0, 0)  # Initial color\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global img\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        # Display RGB components of the pixel under the cursor\n",
    "        if img is not None:\n",
    "            pixel = img[y, x]\n",
    "            # Clear previous marker\n",
    "            img_with_marker = img.copy()\n",
    "            # Draw a circle to indicate the current pixel under the cursor\n",
    "            cv2.circle(img_with_marker, (x, y), 5, (0, 255, 0), -1)\n",
    "            # Calculate text position\n",
    "            text_position = (x - 100, y + 20)\n",
    "            # Display coordinates and RGB components as text\n",
    "            cv2.putText(img_with_marker, f\"X: {x}, Y: {y}, RGB: {pixel}\", text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 0), 1)\n",
    "            cv2.imshow(\"ml.jpg\", img_with_marker)\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Modify the RGB components of the clicked pixel with the new color\n",
    "        if img is not None:\n",
    "            b, g, r = new_color\n",
    "            img[y, x] = [r, g, b]\n",
    "            # Update image with the modified pixel\n",
    "            cv2.imshow(\"ml.jpg\", img)\n",
    "\n",
    "# Callback function for trackbar changes\n",
    "def on_trackbar_change(value):\n",
    "    global new_color\n",
    "    new_color = (cv2.getTrackbarPos('R', 'Color Picker'),\n",
    "                 cv2.getTrackbarPos('G', 'Color Picker'),\n",
    "                 cv2.getTrackbarPos('B', 'Color Picker'))\n",
    "\n",
    "# Opening an image\n",
    "img = cv2.imread(os.path.join(dataDir, 'ml.jpg'))\n",
    "\n",
    "# Showing the image\n",
    "cv2.imshow(\"ml.jpg\", img)\n",
    "\n",
    "# Set mouse callback function\n",
    "cv2.setMouseCallback(\"ml.jpg\", mouse_callback)\n",
    "\n",
    "# Create a window for the color picker\n",
    "cv2.namedWindow('Color Picker', cv2.WINDOW_NORMAL)  # Specify the window size using cv2.WINDOW_NORMAL\n",
    "#cv2.resizeWindow('Color Picker', 200, 100)  # Set the window size (width, height)\n",
    "cv2.createTrackbar('R', 'Color Picker', 0, 255, on_trackbar_change)\n",
    "cv2.createTrackbar('G', 'Color Picker', 0, 255, on_trackbar_change)\n",
    "cv2.createTrackbar('B', 'Color Picker', 0, 255, on_trackbar_change)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2 - Allow the user to select a region of interest (ROI) in the image, by clicking on two points that identify two opposite corners of the selected ROI, and save the ROI into another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI saved to roi.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Global variables to store image and clicked points\n",
    "img = None\n",
    "point1 = None\n",
    "point2 = None\n",
    "click_count = 0\n",
    "\n",
    "def roi_mouse_callback(event, x, y, flags, param):\n",
    "    global point1, point2, click_count, img\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        click_count += 1\n",
    "        if click_count == 1:\n",
    "            point1 = (x, y)\n",
    "        elif click_count == 2:\n",
    "            point2 = (x, y)\n",
    "            click_count = 0\n",
    "\n",
    "            # Draw rectangle around the selected ROI\n",
    "            roi_img = img.copy()\n",
    "            if point1:\n",
    "                cv2.rectangle(roi_img, point1, (x,y), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Image\", roi_img)\n",
    "    \n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        roi_img = img.copy()\n",
    "        if click_count == 1:\n",
    "            cv2.rectangle(roi_img, point1, (x,y), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Image\", roi_img)\n",
    "\n",
    "def save_roi(image, point1, point2, output_file):\n",
    "    # Extract ROI from the original image\n",
    "    roi = image[min(point1[1], point2[1]):max(point1[1], point2[1]), \n",
    "                min(point1[0], point2[0]):max(point1[0], point2[0])]\n",
    "    # Save ROI to another file\n",
    "    cv2.imwrite(output_file, roi)\n",
    "    print(f\"ROI saved to {output_file}\")\n",
    "\n",
    "# Open an image\n",
    "dataDir = './data'\n",
    "image_path = os.path.join(dataDir, 'ml.jpg')\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Image\", img)\n",
    "\n",
    "# Set mouse callback function for selecting ROI\n",
    "cv2.setMouseCallback(\"Image\", roi_mouse_callback)\n",
    "\n",
    "# Wait for user to select ROI\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Check if both points are selected\n",
    "if point1 and point2:\n",
    "    # Save ROI to another file\n",
    "    output_file = \"roi.jpg\"\n",
    "    save_roi(img, point1, point2, output_file)\n",
    "else:\n",
    "    print(\"ROI selection canceled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Images – representation, grayscale and color, color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a white image\n",
    "m = np.ones((100,200,1), np.uint8)\n",
    "\n",
    "# Change the intensity to 100\n",
    "m = m * 100\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Grayscale image', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Grayscale image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line with thickness of 5 px\n",
    "cv2.line(m, (0,0), (200,100), 255, 5)\n",
    "cv2.line(m, (200, 0), (0, 100), 255, 5)\n",
    "cv2.imshow('Grayscale image with diagonals', m)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('Grayscale image with diagonals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1 - Create a color image with 100(lines)x200(columns) pixels with yellow color; draw the two diagonals of the image, one in red color, the other in blue color. Display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a white image\n",
    "height, width = 100, 200\n",
    "yellow_color = (0, 255, 255)  # Yellow color in BGR format\n",
    "color_img = np.full((height, width, 3), yellow_color, dtype=np.uint8)\n",
    "\n",
    "# Draw diagonals with different colors\n",
    "cv2.line(color_img, (0, 0), (width, height), (0, 0, 255), 5)  # Red diagonal\n",
    "cv2.line(color_img, (width, 0), (0, height), (255, 0, 0), 5)  # Blue diagonal\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Color image with diagonals', color_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2 - Read any color image, in RGB format, display it in one window, convert it to grayscale, display the grayscale image in another window and save the grayscale image to a different file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.3 - Split the 3 RGB channels and show each channel in a separate window. Add a constant value to one of the channels, merge the channels into a new color image and show the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.4 - Convert the image to HSV, split the 3 HSV channels and show each channel in a separate window. Add a constant value to saturation channel, merge the channels into a new color image and show the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Video – acquisition and simple processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a VideoCapture Object\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "frame_nr = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    # Wait for user to press s to save frame\n",
    "    if cv2.waitKey(1) == ord('s'):\n",
    "        frame_name = 'frame' + str(frame_nr) + '.png'\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        cv2.imshow(\"Saved frame: \" + frame_name, frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Saved frame: \" + frame_name)\n",
    "\n",
    "    # Wait for user to press q to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_nr += 1\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.1 - Using the previous example as the baseline, implement a script that acquires the video from the webcam, converts it to grayscale, and shows the frames in binary format (i.e. the intensity of each pixel is 0 or 255); use a threshold value of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.2 - Implement a simple detection/tracking algorithm for colored objects, using the following steps:\n",
    "1) take each frame of the video;\n",
    "2) convert from BGR to HSV color-space;\n",
    "3) threshold the HSV image for a range of color values (creating a binary image);\n",
    "4) extract the objects of the selected range (with a bitwise AND operation, using as operands the original and the binary image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
